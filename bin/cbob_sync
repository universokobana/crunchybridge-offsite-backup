#!/bin/bash

# Author: Rafael Lima (https://github.com/rafaelp)
# Dependencies: aws-cli, slack, flock, jq packages

# terminate script as soon as any command fails
set -e

function info(){
    msg="$1"
    echo -e "$(date "+%F %T") INFO: $msg"
    logger -p user.notice -t "$(basename "$0")" "$msg"
    notify "$msg"
}
function warning(){
    msg="$1"
    echo -e "$(date "+%F %T") \e[33mWARN:\e[0m $msg"
    logger -p user.notice -t "$(basename "$0")" "$msg"
    notify ":warning: $msg"
    return 1
}
function error(){
    msg="$1"
    echo -e "$(date "+%F %T") \e[91mERROR:\e[0m $msg"
    logger -p user.error -t "$(basename "$0")" "$msg"
    notify ":octagonal_sign: $msg"
    # remove lock file
    if [ -f "${lock}" ]; then rm "${lock}"; fi
    exit 1
}

function notify () {
  if [[ -n "$CBOB_SLACK_CLI_TOKEN" ]]; then
    export SLACK_CLI_TOKEN=$CBOB_SLACK_CLI_TOKEN
    if ! command -v slack &> /dev/null; then
      CBOB_SLACK_CLI_TOKEN=""
      warning "slack could not be found. Please install the slack script in /usr/local/bin"
      exit 1
    fi
    (slack chat send --text "$1" --channel "$CBOB_SLACK_CHANNEL" >/dev/null) || true
  fi
}

USR=$(whoami)
if [ "$USR" != 'postgres' ]; then
  error "$0 must be run as postgres. Run $ sudo -u postgres $0"
fi

# check if jq exists
if ! command -v jq &> /dev/null
then
    warning "jq could not be found. Please install the jq package"
    exit
fi

# check if flock exists
if ! command -v flock &> /dev/null
then
    warning "flock could not be found. Please install the flock package"
    exit
fi

# check if aws exists
if ! command -v aws &> /dev/null
then
    warning "aws could not be found. Please install the AWS CLI package before continuing. More info at https://aws.amazon.com/cli"
    exit
fi

# Lock file
lock="/tmp/cb_offsite_backup.lock"
exec 9>"${lock}"
flock -n 9 || exit

if [[ -z "$TZ" ]]; then
  TZ=UTC
fi

if [ -n "${CBOB_CONFIG_FILE}" ]; then
  CONFIG_FILE="$CBOB_CONFIG_FILE"
elif [ -r "${HOME}/.cb_offsite_backup" ] && [ -f "${HOME}/.cb_offsite_backup" ]; then
  CONFIG_FILE="${HOME}/.cb_offsite_backup"
elif [ -r "/usr/local/etc/cb_offsite_backup" ] && [ -f "/usr/local/etc/cb_offsite_backup" ]; then
  CONFIG_FILE="/usr/local/etc/cb_offsite_backup"
elif [ -r "/etc/cb_offsite_backup" ] && [ -f "/etc/cb_offsite_backup" ]; then
  CONFIG_FILE="/etc/cb_offsite_backup"
fi

if [[ -z "$CONFIG_FILE" ]]; then
  error "Config file not found!"
fi

if [ -f $CONFIG_FILE ]; then
  info "Reading config file $CONFIG_FILE"
  unamestr=$(uname)
  if [ "$unamestr" = 'Linux' ]; then
    export $(grep -v '^#' $CONFIG_FILE | xargs -d '\n')
  elif [ "$unamestr" = 'FreeBSD' ] || [ "$unamestr" = 'Darwin' ]; then
    export $(grep -v '^#' $CONFIG_FILE | xargs -0)
  fi
fi

if [[ -z "$CBOB_LOG_PATH" ]]; then
  info "Missing CBOB_LOG_PATH variable. Setting the default '/var/log'"
  CBOB_LOG_PATH="/var/log"
fi

# Log file
log="$CBOB_LOG_PATH/cb_offsite_backup.log"
touch "${log}"
exec &> >(tee -a "${log}")

if [[ -z "$CBOB_CRUNCHY_CLUSTERS" ]]; then
  warning "Missing CBOB_CRUNCHY_CLUSTERS variable which must be set with the IDs of clusters from Crunchy Bridge"
  exit
fi

if [[ -z "$CBOB_TARGET_PATH" ]]; then
  warning "Missing CBOB_TARGET_PATH variable which must be set with the path where the files should be synced. Ex: $ export TARGET_PATH=/mnt/volume_backup/pgbackrest/"
  exit
fi

if [[ -z "$CBOB_CRUNCHY_API_KEY" ]]; then
  error "Missing CBOB_CRUNCHY_API_KEY variable which must be set with the token of Crunchy Bridge API. To create an API key go to: https://crunchybridge.com/account/api-keys"
fi

info "Crunchy Bridge Offsite Backup started!"

IFS=',' # delimiter
read -ra CLUSTER_IDS <<< "$CBOB_CRUNCHY_CLUSTERS" # str is read into an array as tokens separated by IFS
for CLUSTER_ID in "${CLUSTER_IDS[@]}"; do # access each element of array
  IFS=''

  info "Starting Sync of cluster *$CLUSTER_ID*"

  info "  -> Getting Last Backup for $CLUSTER_ID"
  LAST_BACKUP=$(curl -s -X GET "https://api.crunchybridge.com/clusters/$CLUSTER_ID/backups?limit=1&order=desc" -H "Authorization: Bearer $CBOB_CRUNCHY_API_KEY")
  export LAST_BACKUP_NAME=$(echo $LAST_BACKUP | jq -r '.backups[0].name')
  info "     Last backup for $CLUSTER_ID is $LAST_BACKUP_NAME"

  info "  -> Getting Credentials for $CLUSTER_ID"
  CREDENTIALS=$(curl -s -X POST "https://api.crunchybridge.com/clusters/$CLUSTER_ID/backup-tokens" -H "Authorization: Bearer $CBOB_CRUNCHY_API_KEY")

  # Log credentials, do not do it in production
  # echo $CREDENTIALS | jq .

  AWS_CONFIG=$(echo $CREDENTIALS | jq -r '.aws')
  if [ "$AWS_CONFIG" == "null" ]; then
    error "Could not get credentials for CLUSTER $CLUSTER_ID"
  fi

  export AWS_REGION=$(echo $CREDENTIALS | jq -r '.aws.s3_region')
  export AWS_SESSION_TOKEN=$(echo $CREDENTIALS | jq -r '.aws.s3_token')
  export AWS_ACCESS_KEY_ID=$(echo $CREDENTIALS | jq -r '.aws.s3_key')
  export AWS_SECRET_ACCESS_KEY=$(echo $CREDENTIALS | jq -r '.aws.s3_key_secret')

  AWS_S3_BUCKET=$(echo $CREDENTIALS | jq -r '.aws.s3_bucket')
  REPO_PATH=$(echo $CREDENTIALS | jq -r '.repo_path')
  STANZA=$(echo $CREDENTIALS | jq -r '.stanza')

  if [ "$REPO_PATH" == "null" ]; then
    warning "Missing REPO_PATH for CLUSTER $CLUSTER_ID"
  fi

  if [ "$STANZA" == "null" ]; then
    warning "Missing STANZA for CLUSTER $CLUSTER_ID"
  fi

  # info "  -> Calculating backup size for $CLUSTER_ID..."
  # LS_OUTPUT=$(aws s3 ls --summarize --human-readable --recursive "s3://$AWS_S3_BUCKET$REPO_PATH/archive/$STANZA/$LAST_BACKUP_NAME")
  # BUCKET_SIZE=$(echo "$LS_OUTPUT" | grep 'Archive Total Size:' | cut -f2 -d":" | xargs)
  # info "  -> Backup size for $CLUSTER_ID: $BUCKET_SIZE"

  if [[ "$CBOB_DRY_RUN" == "true" ]]; then
    info "  -> Dry-run sync from AWS S3 to $CBOB_TARGET_PATH"
    notify "Backup of *$CLUSTER_ID* is not running because DRY_RUN is set."
    aws s3 sync --dryrun "s3://$AWS_S3_BUCKET$REPO_PATH/archive/$STANZA" "$CBOB_TARGET_PATH/archive/$STANZA"
    aws s3 sync --dryrun "s3://$AWS_S3_BUCKET$REPO_PATH/backup/$STANZA/$LAST_BACKUP_NAME" "$CBOB_TARGET_PATH/backup/$STANZA/$LAST_BACKUP_NAME"
    aws s3 sync --dryrun "s3://$AWS_S3_BUCKET$REPO_PATH/backup/$STANZA/backup.history" "$CBOB_TARGET_PATH/backup/$STANZA/backup.history"
    aws s3 cp --dryrun "s3://$AWS_S3_BUCKET$REPO_PATH/backup/$STANZA/backup.info" "$CBOB_TARGET_PATH/backup/$STANZA/backup.info"
    aws s3 cp --dryrun "s3://$AWS_S3_BUCKET$REPO_PATH/backup/$STANZA/backup.info.copy" "$CBOB_TARGET_PATH/backup/$STANZA/backup.info.copy"
  else
    info "  -> Syncing from AWS S3 to $CBOB_TARGET_PATH"
    aws s3 sync "s3://$AWS_S3_BUCKET$REPO_PATH/archive/$STANZA" "$CBOB_TARGET_PATH/archive/$STANZA"
    aws s3 sync "s3://$AWS_S3_BUCKET$REPO_PATH/backup/$STANZA/$LAST_BACKUP_NAME" "$CBOB_TARGET_PATH/backup/$STANZA/$LAST_BACKUP_NAME"
    aws s3 sync "s3://$AWS_S3_BUCKET$REPO_PATH/backup/$STANZA/backup.history" "$CBOB_TARGET_PATH/backup/$STANZA/backup.history"
    aws s3 cp "s3://$AWS_S3_BUCKET$REPO_PATH/backup/$STANZA/backup.info" "$CBOB_TARGET_PATH/backup/$STANZA/backup.info"
    aws s3 cp "s3://$AWS_S3_BUCKET$REPO_PATH/backup/$STANZA/backup.info.copy" "$CBOB_TARGET_PATH/backup/$STANZA/backup.info.copy"
  fi

  info ":white_check_mark: Sync of *$CLUSTER_ID* complete"
done

if [[ -n "$CBOB_SYNC_HEARTBEAT_URL" ]]; then
  info "Sending a request to the specified CBOB_SYNC_HEARTBEAT_URL that the backup was created"
  curl -s $CBOB_SYNC_HEARTBEAT_URL
  info "heartbeat complete"
fi

# remove lock file
if [ -f "${lock}" ]; then
    rm "${lock}"
fi

info ":checkered_flag: All backups complete!"

exit